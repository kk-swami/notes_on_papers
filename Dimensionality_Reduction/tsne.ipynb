{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Data using t-sne\n",
    "###  Journal of Machine Learning Research 9 (2008) 2579-2605 (Maaten and Hinton)\n",
    "\n",
    "## One Line Summary\n",
    "New visualization scheme to visualize high dimension data in low dimensions (2 or 3) - Improvement of TSNE by\n",
    "\n",
    "- using joint probabilities instead of conditional probabilies for measuring pairwise similarity between points in both high and low dimensional spaces - ie uses $p_{ij}$ and $q_{ij}$ instead of $p_{i|j}$ and $q_{i|j}$ .  This leads to a symmetric formulations of $p_{ij}$ and $q_{ij}$ unlike sne, leading to simpler gradients\n",
    "\n",
    "\n",
    "- for $q_{ij}$ (low dimension space) - uses a t distribution instead of a gaussian ( t is heavy tailed, so better , avoids crowding problem)\n",
    "  - What is crowding problem ?\n",
    "  - From SNE cost function, penalty is lesser for point pairs with low $p_{j|i}$ and high $q_{j|i}$ - points seperated in original space, closer in lower dimensional space - this leads to points in priginal space being crowded in the lower dimensional space.\n",
    "  Having a heavy tailed distribution in the lower dimensional space counteracts this behavior a bit, doesn't crowd points in lower dimensional space as much as guassian\n",
    "\n",
    "\n",
    "  ## The Math\n",
    "\n",
    "  From SNE,\n",
    "\n",
    "  p<sub>j|i</sub> = $\\frac{e^{-\\frac{|x^{i}-x^{j}|^{2}}{2\\sigma_i^{2}}}}{\\sum_{k,k!=i}{e^{-\\frac{|x^{i}-x^{k}|^{2}}{2\\sigma_i^{2}}}}}$\n",
    "\n",
    "\n",
    "Similarity of points in high dimensioan space p<sub>ij</sub>\n",
    "  p<sub>ij</sub> = 0.5*(p<sub>i|j</sub> + p<sub>j|i</sub>)\n",
    " - Note that this is symmetric\n",
    "\n",
    " $q_{ij} = \\frac{{1 + {|y_i-y_j|^{2}}}^{-1}}{\\sum_k\\sum_{l,l!=k}{1 + {|y_k-y_l|^{2}}}^{-1}}$\n",
    "\n",
    "\n",
    "The cost function\n",
    "$C = \\sum_iKL(P_i|Q_i)$ where $P_i$ and $Q_i$ are joint probabilities as defined above\n",
    "\n",
    "  = $\\sum_i\\sum_jp_{ij}ln(\\frac {p_{ij}}{q_{ij}})$\n",
    "\n",
    "\n",
    "The partial derivative of C wrt $y_i$ has the form below\n",
    "$\\frac{\\partial C}{\\partial y_i}$ = $4*\\sum_j(p_{ij}-q_{ij})(y_i-y_j)*(1 + |y_i-y_j|^{2} )^{-1}$\n",
    "\n",
    "\n",
    "Proof -\n",
    "Change indices notation from i,j to k,l for easier derivative wrt $p_{i}$\n",
    "$C = \\sum_k\\sum_lp_{klj}ln(p_{klj}) - \\sum_k\\sum_lq_{kl}ln(q_{kl})$\n",
    "\n",
    "Let $q_{kl}$ = $\\frac{D_{kl}}{Z}$, where $D_{kl}$ = ${1+|y_k-y_l|^{2}}^{-1}$,\n",
    "Z = $\\sum_k\\sum_{l,l!=k}{1 + {|y_k-y_l|^{2}}}^{-1}$\n",
    "Note that Z is independent of k and l\n",
    "\n",
    "Therefore, C = C1 -$\\sum_k\\sum_lp_{kl}ln(D_{kl})$ + $\\sum_k\\sum_lp_{kl}ln(Z)$\n",
    "\n",
    "Where C1 is a function of $p_{kl}$, independent of $y_{i}$\n",
    "\n",
    "Term 1 = C1\n",
    "\n",
    "Term 2 = -$\\sum_k\\sum_lp_{kl}ln(D_{kl})$\n",
    "\n",
    "Term 3 = $\\sum_k\\sum_lp_{kl}ln(Z)$   = $ln(Z)$ as $ln(Z)$ is independent of k and l, and $\\sum_k\\sum_lp_{kl}$ = 1\n",
    "\n",
    "taking partial derivatives,\n",
    "\n",
    "$\\frac{\\partial Term1}{\\partial y_i}$ = $\\frac{\\partial C1}{\\partial y_i}$ = 0  as C1 is independent of $y_{i}$\n",
    "\n",
    "\n",
    "$\\frac{\\partial Term3}{\\partial y_i}$ = $\\frac{1}{Z}\\frac{\\partial Z}{\\partial y_{i}}$\n",
    "\n",
    "\n",
    "\n",
    "Z = $\\sum_k\\sum_{l,l!=k}{1 + {|y_k-y_l|^{2}}}^{-1}$\n",
    "\n",
    "Note that this formulation of Z is symmetric\n",
    "\n",
    "The only terms dependent of $y_{i}$  which will stay after partial differentiation arrive\n",
    "\n",
    "$2*sum_{j,j!=i}{1 + {|y_i-y_j|^{2}}}^{-1}$\n",
    "\n",
    "\n",
    "\n",
    " =  $2*sum_{j,j!=i}D_{ij}$\n",
    "\n",
    " Therefore,  $\\frac{\\partial Z}{\\partial y_{i}}$ = $2*sum_{j,j!=i}\\frac{\\partial D_{ij}}{\\partial y_i}$\n",
    "\n",
    "\n",
    "$D_{ij}$ = ${1 + {|y_i-y_j|^{2}}}^{-1}$\n",
    "\n",
    "$\\frac{\\partial D_{ij}}{\\partial y_i}$ = $-1*D_{ij}^{2}*2*(y_i-y_j)$\n",
    "\n",
    "\n",
    "Therefore,\n",
    "\n",
    "\n",
    "$\\frac{\\partial Term3}{\\partial y_i}$ =  $\\frac{1}{Z}*2*sum_{j,j!=i}(-2*(y_{i}-y_{j})*{D_{ij}}^2)$\n",
    "\n",
    "\n",
    "Taking Z inside the summation,\n",
    "\n",
    "\n",
    "$\\frac{\\partial Term3}{\\partial y_i}$ =\n",
    "\n",
    "-4*$sum_{j,j!=i}((y_i-y_j)*D_{ij}*q_{ij})$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Finally coming to term 2,\n",
    "\n",
    "Term 2 = -$\\sum_k\\sum_lp_{kl}ln(D_{kl})$\n",
    "\n",
    "The only terms dependent on y_i arrive\n",
    "\n",
    "-2*$\\sum_i\\sum_{j,j!=i}p_{ij}ln(D_{ij})$,  where the 2 is because of symmetry\n",
    "\n",
    "\n",
    "Taking partial derivative of term 2 wrt $y_{i}$,\n",
    "\n",
    "$\\frac{\\partial Term2}{\\partial y_i}$ =   $-2*\\sum_i\\sum_{j,j!=i}\\frac{p_{ij}}{D_{ij}}\\frac{\\partial D_{ij}}{\\partial y_i}$\n",
    "\n",
    "\n",
    "Plugging in the form of $\\frac{\\partial D_{ij}}{\\partial y_i}$ from earlier,\n",
    "\n",
    "\n",
    "we get\n",
    "\n",
    "\n",
    "$\\frac{\\partial Term2}{\\partial y_i}$ =\n",
    "\n",
    "\n",
    "$-2*\\sum_i\\sum_{j,j!=i}\\frac{p_{ij}}{D_{ij}}*-2*{D_{ij}}^2*(y_{i}-y_{j})$\n",
    "\n",
    "\n",
    "= $4*\\sum_i\\sum_{j,j!=i}p_{ij}{D_{ij}}*(y_{i}-y_{j})$\n",
    "\n",
    "Adding the 3 derivatives, we get the expected answer\n",
    "\n",
    "\n",
    "    $\\frac{\\partial C}{\\partial y_i}$ = $\\sum_j4*D_{ij}(y_{i}-y_{j})(p_{ij}-q_{ij})$\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
